{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gMnY4ESvfEA"
   },
   "source": [
    "# HPC as a solution for AI: PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wHXE1ij1bIA"
   },
   "source": [
    "<p style='text-align: justify;'>\n",
    "In this section, it will be shown how to optimize PyTorch models, accelerating training and execution using GPUs.\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principal gols are:\n",
    "* **Use** the PyTorch library on GPU environments for the first time to accelerate the training of image classification models,\n",
    "* **Familiarize** yourself with the CIFAR-10 and CIFAR-100 dataset by classifying their various classes,\n",
    "* **Evaluate** and **Compare** the performance of your models on GPU and CPU environments to understand the benefits of GPU acceleration in AI tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmwBTXpn1bIA"
   },
   "source": [
    "## The problem: Resource-intensive training and model scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vP0wr4R51bIA"
   },
   "source": [
    "<p style='text-align: justify;'>\n",
    "As AI research progresses, deep neural networks have become critical for tasks like image generation and language translation. However, resource-intensive training challenges arise as networks become more complex and demanding in performance.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "Research and development in artificial intelligence have made remarkable strides in recent decades, mainly driven by deep neural networks. These networks are computational structures loosely inspired by the functioning of the human brain. They are particularly well-suited for tasks that involve large volumes of data, such as pattern recognition in images, natural language processing, and more.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "However, as the problems being addressed become more complex and performance demands increase, the need for computational resources also grows exponentially. Additionally, the scalability of these models becomes a concern as they grow in size and complexity. Maintaining and optimizing constantly expanding AI models becomes challenging for the research and development community.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ4Teb2m1bIA"
   },
   "source": [
    "## The solution: GPUs and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ST3ronAy1bIA"
   },
   "source": [
    "<p style='text-align: justify;'>\n",
    "Using libraries like PyTorch, a popular machine learning and AI framework, offers a flexible interface for designing, training, and evaluating neural networks using GPUs, especially when harnessed with computational prowess.\n",
    "</p>\n",
    "<p style='text-align: justify;'>\n",
    "Furthermore, Intel® PyTorch is well equipped to fully utilize the optimizations and hardware support of Intel® processors and GPUs. This synergy results in an even more efficient and performance-oriented machine-learning experience. It enables practitioners to extract maximum computational throughput from their hardware infrastructure.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMvo8TG2WWZE"
   },
   "source": [
    "##  ☆ Challenge: Zoo breakout!☆ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "    Recently, an unexpected incident occurred at the local zoo, <b>Orange Grove Zoo</b>: all the animals escaped from their enclosures and are now roaming freely. To deal with this situation, we need your help locating and classifying the escaped animals, distinguishing each animal class, and identifying possible vehicles in the same environment.\n",
    "</p>\n",
    "<p style='text-align: justify;'> \n",
    "You have been assigned as the person responsible for developing a computer vision system capable of identifying and classifying the escaped animals and identifying the presence of vehicles in the images. We will use the CIFAR-10 dataset and the TensorFlow library to train a deep-learning model for this challenge.\n",
    "</p>\n",
    "CIFAR-10 and CIFAR-100 datasets comprehensively collect $32$x$32$ pixel images grouped into $10$ distinct classes.\n",
    "\n",
    "- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-10 consists of $60,000$ images, each belonging to one of the ten classes: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. This dataset offers a diverse set of images representing everyday objects.\n",
    "\n",
    "- [CIFAR-100 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-100 expands upon the CIFAR-10 concept, containing 60,000 images as well. However, it introduces a more challenging task by categorizing images into 100 classes. These classes include various subcategories such as fruits, animals, vehicles, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9pJ2tDOCaN6"
   },
   "source": [
    "a) **Create** deep neural network model utilizing the PyTorch library for the classification of animals and vehicles on a GPU environment using the CIFAR-10 dataset.\n",
    "\n",
    "b) **Conduct** a comparative analysis between models trained on a CPU and GPU to highlight disparities in results.\n",
    "\n",
    "c) Now, use the CIFAR-100 dataset for the classification of animals and vehicles on a GPU. Would it be a good decision to use a GPU or CPU environment for the training process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_Ch1ZPO1bIC"
   },
   "source": [
    "### ☆  Solution for CIFAR-10 using PyTorch on a GPU  ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Define processing device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Transformations to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the data preparation process, we create a ```transforms``` object to apply specific transformations to the data. These transformations are commonly used in training datasets to enhance data diversity and ready images for utilization in a deep learning model, such as a convolutional neural network (CNN). I will provide a detailed explanation of each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that, download the CIFAR-10 dataset and load it into the code. Define the neural network as we have done in previous notebooks, and remember to move this network instance to the previously defined device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "gpu_start_time = time.time()\n",
    "\n",
    "for epoch in range(10):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}')\n",
    "\n",
    "gpu_end_time = time.time()\n",
    "\n",
    "print(f'GPU Training time: {gpu_end_time - gpu_start_time}')\n",
    "\n",
    "torch.save(net.state_dict(), 'cifar10_gpu_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments about the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "We explored training neural networks with PyTorch, comparing CPU and GPU performance on the CIFAR-10 dataset. When utilizing the CPU environment, the process can be executed in approximately <b>811 seconds or (13.52 minutes)</b>. However, when employed in the GPU environment with PyTorch, the execution time was reduced to approximately <b>191 seconds or (3.2 minutes)</b>. This outcome illustrates that the GPU has achieved nearly a <b>Speedup of 4X</b> compared to the CPU when running with 10 epochs. Thanks to its parallel computing capabilities, the GPU has substantially enhanced the training speed, which is particularly advantageous for handling extensive data and intricate models in deep learning.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCCcZ7Q31bIC"
   },
   "source": [
    "## Summary\n",
    "In this notebook we have shown: \n",
    "\n",
    "- Install and use PyTorch using GPU environments,\n",
    "- Comparative performance tests between CPU and GPU on model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FolLqE_1bID"
   },
   "source": [
    "## Clear the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXiePpX31bID"
   },
   "source": [
    "Before moving on, please execute the following cell to clear up the CPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMB90WpX1bID"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbgrxWUP1bIE"
   },
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RniCDPdQ1bIE"
   },
   "source": [
    "Congratulations on finishing the HPC simulations topic!! You have completed the last part of the learning objectives of this part of the course! As a final exercise, complete an applied problem in the assessment in [_04-hpc-simulations-assessment.ipynb_](04-hpc-simulations-assessment.ipynb)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9712f6e",
   "metadata": {},
   "source": [
    "# HPC as solutions for AI: TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca98a4",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "In this section, it will be shown how to optimize Tensorflow models, accelerating training and execution using GPUs.\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5a80bd-2076-4834-ad32-588e2424d4a4",
   "metadata": {},
   "source": [
    "The principal gols are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033cf2fc",
   "metadata": {},
   "source": [
    "* **Understand** what is Tensorflow,\n",
    "* **Learn** the basic concepts of Tensorflow for GPUs,\n",
    "* **Create** a model using Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519cfc5",
   "metadata": {},
   "source": [
    "## What use Tensorflow in IA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90331c7b",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7b378",
   "metadata": {},
   "source": [
    "## The solution: GPUs and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccba001",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf4e20-c662-4b55-afb1-3a72692d53b7",
   "metadata": {
    "id": "BMvo8TG2WWZE"
   },
   "source": [
    "##  ☆ Challenge: Zoo breakout!☆ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4774de4-7d64-4d33-be59-745d12d8029c",
   "metadata": {},
   "source": [
    "Recently, there was an unexpected incident at the local zoo, **Orange Grove Zoo**: all the animals escaped from their enclosures and are now roaming freely in the zoo. To deal with this situation, we need your help to locate and classify the escaped animals, distinguishing each animal class and identifying possible vehicles that may be in the same environment.\n",
    "\n",
    "You have been assigned as the person responsible for developing a computer vision system capable of identifying and classifying the escaped animals, as well as identifying the presence of vehicles in the images. For this challenge, we will use the CIFAR-10 dataset and the PyTorch library to train a deep learning model.\n",
    "\n",
    "CIFAR-10 and CIFAR-100 datasets provide a comprehensive collection of 32x32 pixel images, grouped into 10 and 100 distinct classes, respectively.\n",
    "\n",
    "- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-10 consists of 60,000 images, each belonging to one of the ten classes: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. This dataset offers a diverse set of images representing everyday objects.\n",
    "\n",
    "- [CIFAR-100 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-100 expands upon the CIFAR-10 concept, containing 60,000 images as well. However, it introduces a more challenging task by categorizing images into 100 classes. These classes include various subcategories such as fruits, animals, vehicles, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac15552-86f2-42e2-a62d-ad0b875d46a0",
   "metadata": {
    "id": "X9pJ2tDOCaN6"
   },
   "source": [
    "a) **Create** deep neural network model utilizing the PyTorch library for the classification of animals and vehicles on a CPU and on a GPU using CIFAR-10 dataset.\n",
    "\n",
    "b) **Conduct** a comparative analysis between models trained on CPU and GPU to highlight disparities in results.\n",
    "\n",
    "c) Now, use the CIFAR-100 dataset for the classification of animals and vehicles on a GPU. Would it be a good decision to use a GPU or a CPU for the training process?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3fab8-7a7d-4977-aa9f-3fbc73eb5ec0",
   "metadata": {
    "id": "8_Ch1ZPO1bIC"
   },
   "source": [
    "### ☆ Solution ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983edbde",
   "metadata": {},
   "source": [
    "#### ⊗ Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fc965",
   "metadata": {},
   "source": [
    "#### ⊗ Verify the devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d046e",
   "metadata": {},
   "source": [
    "It is very important, before trying to execute anything on any device, to verify if it is available and if TensorFlow can use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4db73c",
   "metadata": {},
   "source": [
    "##### ⊗ Checking CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a71d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if CPU is available\n",
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "if not cpus:\n",
    "    raise RuntimeError(\"No CPU available.\")\n",
    "else:\n",
    "    print(\"CPU available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5ad9f",
   "metadata": {},
   "source": [
    "##### ⊗ Checking GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49480c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if GPU is available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if not gpus:\n",
    "    raise RuntimeError(\"No GPU available.\")\n",
    "else:\n",
    "    print(\"GPU available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7adb41f",
   "metadata": {},
   "source": [
    "#### ⊗ Downloading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51d0b28",
   "metadata": {},
   "source": [
    "Now we need to download the cifar10 dataset to be able to make predictions. Cifar10 is a dataset of labeled images, meaning that each image to be loaded already has a known label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2746c",
   "metadata": {},
   "source": [
    "#### ⊗ Normalizing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c993dd",
   "metadata": {},
   "source": [
    "After downloading the entire set of images, we need to normalize them so that we can use them in our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07245e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing pixel values to the [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89668fca",
   "metadata": {},
   "source": [
    "#### ⊗ Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897219e2",
   "metadata": {},
   "source": [
    "Now it is necessary to create the model for our neural network, notice that this step becomes extremely simple using the power of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68966139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d471eacd",
   "metadata": {},
   "source": [
    "#### ⊗ Compiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46e18e6",
   "metadata": {},
   "source": [
    "After creating the model, it needs to be compiled, just as we did in the first example with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136107e",
   "metadata": {},
   "source": [
    "#### ⊗ Training Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a459e",
   "metadata": {},
   "source": [
    "Now it is important to define the training function of the model, which it will use to train using the Cifar10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375da0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model and measure time with progress\n",
    "def train_model(device, train_images, train_labels):\n",
    "    with tf.device(device):\n",
    "        start_time = time.time()\n",
    "        history = model.fit(train_images, train_labels, epochs=100, \n",
    "                    validation_data=(test_images, test_labels), verbose=1)\n",
    "        end_time = time.time()\n",
    "    \n",
    "    return history, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86365792",
   "metadata": {},
   "source": [
    "#### ⊗ Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c694e7d",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> The next step is to perform the model training. Note that in the step below, we will use the GPU to train the model and then the CPU to train and compare their execution times. (Depending on the GPU and CPU of your machine, this step may take some time). </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b321581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dataset for training and testing (e.g., 20% of the original data)\n",
    "fraction_of_data = 1\n",
    "num_samples = int(len(train_images) * fraction_of_data)\n",
    "\n",
    "small_train_images = train_images[:num_samples]\n",
    "small_train_labels = train_labels[:num_samples]\n",
    "small_test_images = test_images[:num_samples]\n",
    "small_test_labels = test_labels[:num_samples]\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# # Train the model on the CPU with the reduced dataset\n",
    "# cpu_history, cpu_time = train_model('/CPU:0', small_train_images, small_train_labels)\n",
    "# print(f\"Training time on CPU: {cpu_time:.2f} seconds\")\n",
    "\n",
    "# Train the model on the GPU with the reduced dataset\n",
    "gpu_history, gpu_time = train_model('/GPU:0', small_train_images, small_train_labels)\n",
    "print(f\"Training time on GPU: {gpu_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed827a",
   "metadata": {},
   "source": [
    "#### ⊗ Evaluating Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9befbbf7",
   "metadata": {},
   "source": [
    "In the last step, we only need to evaluate the accuracy of the model we created. For didactic purposes, we will plot the result on a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7f1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"\\nModel accuracy on the test set:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f1aeb",
   "metadata": {},
   "source": [
    "#### ⊗ Evaluating the Learning Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894189b9",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> After evaluating the accuracy that our model achieved, it is interesting to understand its learning curve during training, both on GPU and CPU. Below is the code responsible for plotting this curve on a graph. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07def6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(gpu_history.history['accuracy'], label='accuracy (GPU)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(gpu_history.history['val_accuracy'], label='val_accuracy (GPU)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f43b0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook we have shown: \n",
    "\n",
    "- Install and use Tensorflow using **GPU** environments,\n",
    "- Comparative performance tests between **CPU** and **GPU** on model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e8dad",
   "metadata": {},
   "source": [
    "## Clear the memory\n",
    "Before moving on, please execute the following cell to clear up the CPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3945a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import IPython\n",
    "#app = IPython.Application.instance()\n",
    "#app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b52915-f34b-480a-ac98-dc48f82bd007",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ebb05e",
   "metadata": {},
   "source": [
    "In this section, you learned how to use a Tensorflow in a simple example using a GPU environment. In the next section, you will learn about other applications that those devices can be pretty useful in [_03-hpc-simulations-pytorch.ipynb_](03-hpc-simulations-pytorch)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

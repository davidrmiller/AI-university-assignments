{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21d5059-73b7-456c-82ea-f1a605a0ad14",
   "metadata": {
    "tags": []
   },
   "source": [
    "# High-performance computing applied in AI applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad37b173-ed95-46f5-bdf0-0bdf3016caed",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "High-performance computing, known as HPC, is a field of modern computing whose goal is to solve computational problems of high complexity and large volumes of data by operating by dividing complex problems into smaller parts that are processed simultaneously by several processors, accelerating the resolution time. HPC enables scientists, engineers, and researchers to perform highly detailed simulations, massive data analysis, and precise modeling that would be impractical or unachievable using conventional systems.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "HPC systems are designed to handle large volumes of data and perform intensive calculations in a fraction of the time it would take on conventional computers. An HPC comprises one or several supercomputers of interconnected high-performance processors, large amounts of memory, and fast storage to handle intensive workloads.\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"./images/figure01_ponte_vecchio.jpg\" style=\"width: 500px;\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b762f150-1969-42e6-b8ce-dbb31fbebb96",
   "metadata": {},
   "source": [
    "## ⊗ **Why use parallel computing?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0cc88-a7de-4cb6-8b31-40f3d1de4692",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>   \n",
    "Parallel computing is widely used in many areas such as scientific simulations, graphics rendering, big data analysis, machine learning, artificial intelligence, image processing and many more. There are several approaches to implementing parallel computing, of which we can include data parallelism, task parallelism, instruction parallelism, bit-level parallelism, thread-level parallelism, among others.\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"./images/figure02_parallel_computing.png\" style=\"width: 1000px;\">\n",
    "</div>\n",
    "\n",
    "<p style='text-align: justify;'>   \n",
    "One of the main gains parallel computing provides is the remarkable performance acceleration. You can get more work done in less time by running multiple tasks simultaneously. This aspect is particularly advantageous for solving complex problems that often involve intensive calculations or the analysis of vast data sets.\n",
    "Parallel computing is essential for dealing with the growing data generated in our digital world. In machine learning and artificial intelligence, training complex models in parallel is critical for creating effective AI systems in areas such as pattern recognition, natural language processing, and computer vision.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'> \n",
    "HPC and parallel computing can be used in several scenarios. Let's meet some of them below.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a215da7-040a-4598-8772-bf1e990001fa",
   "metadata": {},
   "source": [
    "## ⊗ **HPC applied in AI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22840e1e-0850-4e66-90db-d1f795bb6ea6",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "HPC plays a key role when it comes to applications using Artificial Intelligence, since a large computational power is needed to be able to train increasingly complex AI models and perform analyzes on massive data sets.\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"./images/figure03_aurora_supercomputing.jpg\" style=\"width: 500px;\">\n",
    "</div>\n",
    "    \n",
    "<p style='text-align: justify;'> \n",
    "A notable example is Intel's Aurora supercomputer, which plays a key role in research areas as diverse as neuroscience, aerospace simulation, universe exploration, and artificial intelligence. These surveys require an extremely high processing capacity,\n",
    "making the application of structures such as HPC essential. Conducting research in this direction requires the use of computational algorithms capable of dealing with large volumes of data and that also have resources for implementing artificial intelligence solutions. For example, in neuroscience research,\n",
    "Aurora can help simulate complex neural networks and analyze brain data at scale, leading to advances in understanding neurological disorders and developing more effective treatments.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "In aerospace simulations and exploration of the universe, Aurora allows the modeling of complex phenomena, such as the behavior of planetary systems and aircraft flight dynamics, contributing to space exploration and the development of more advanced technologies. In summary, the intersection between HPC and life science research, space and AI drives scientific discoveries and technological advances that have the potential to transform our lives and our understanding of the world around us.\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d0c4c-17a0-481f-928b-cc669f30c1ec",
   "metadata": {},
   "source": [
    "## ⊗ **HPC uses cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c833036e-082b-4f1d-88f7-05ffa4221acd",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "HPC is often used in fields where processing requirements are extraordinarily high and exceed the capabilities of conventional computer systems. Here are some examples of HPC use cases:\n",
    "</p>\n",
    "    \n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"./images/figure01_hpc_applications.png\" style=\"width: 500px;\">\n",
    "</div>\n",
    "\n",
    "* **Machine learning and artificial intelligence:** training complex machine learning models requires a lot of computing power. HPC allows you to train models faster and handle larger datasets, resulting in advances in AI, pattern recognition and data analysis;\n",
    "\n",
    "* **Biomedical research:** HPC accelerates the virtual screening of molecules, assessing how they interact with target proteins. This streamlines the drug discovery process, saving time and resources;\n",
    "\n",
    "* **Aerodynamics and flight simulation:** the aerospace industry uses HPC to simulate the behavior of aircraft,improve wing design, optimize fuel efficiency and study aerodynamics;\n",
    "\n",
    "* **Exploration of natural resources and petroleum:** the simulation of oil and gas reservoirs, as well as the exploration of mineral resources, require complex models and intensive calculations. HPC helps make informed decisions about locating and exploiting these resources;\n",
    "\n",
    "* **Particle physics:** particle physics research requires HPC to analyze data generated by particle accelerators such as the LHC (Large Hadron Collider);\n",
    "\n",
    "* **Scientific research and simulations:** HPC allows the modeling of natural phenomena and processes that would be almost impossible to observe experimentally. For example, simulating particle interactions in a particle accelerator or simulating long-term weather processes.\n",
    "\n",
    "<p style='text-align: justify;'> \n",
    "These are just a few examples of the many use cases for HPC. In general, it plays a crucial role in areas that need advanced computational capacity to solve complex problems, often driving innovation and scientific and technological progress.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c549e24-b460-4f22-8cea-0b32287d71d4",
   "metadata": {},
   "source": [
    "## **HPC as solutions for AI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e4518c-36e7-4d4b-a3d1-aa1a62981587",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "When we want to deal with a large volume of information in artificial intelligence applications, aiming to substantially reduce the time required to solve the problem, it is essential that specific software tools are implemented for this purpose. Let's now explore three of the most prominent libraries: <b>TensorFlow</b> and <b>PyTorch</b>. These tools play a central role in creating and training AI models in processing-intensive environments, let's get to know each one of them.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72b0a4-8133-45ea-9acf-a5df54845269",
   "metadata": {},
   "source": [
    "### ⊗ **Tensorflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf342a08-64df-4712-9943-25d9a01f3173",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "TensorFlow is an open-source library focusing on high-performance numerical computing, especially suited for training and deploying machine learning and deep learning models. It is used in various applications, from computer vision to natural language processing. Keras was a standalone library for deep learning, but since TensorFlow 2.0, it has been integrated into TensorFlow as its high-level API for building and training neural networks. Keras is known for its simplicity and ease of use,\n",
    "being a popular choice for beginning developers and for rapid prototyping of deep learning models.\n",
    "</p>\n",
    "    \n",
    "<p style='text-align: justify;'>\n",
    "Let's see how we can access and use our GPU for training a simple neural network using TensorFlow and keras.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d194d0-9328-435f-abaf-4746de85e2c7",
   "metadata": {},
   "source": [
    "#### **Checking GPU availability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27db308b-c108-489d-aef4-17dcc9ead7e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check for available GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    # Configure GPU memory allocation dynamically\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    # Display information about available GPU\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"GPU {i + 1}: {gpu.name}\")\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93378488-1958-4169-8851-9634c3fa9246",
   "metadata": {},
   "source": [
    "####  **Creating a neural network with Tensorflow + Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c513f92-82c8-4db9-8d0f-86f0ebceadc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.7790 - accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7787 - accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7783 - accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7780 - accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7776 - accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7773 - accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7769 - accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7766 - accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7762 - accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7759 - accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7756 - accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7752 - accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7749 - accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7745 - accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7742 - accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7738 - accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7735 - accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7732 - accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7728 - accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7725 - accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7722 - accuracy: 0.7500\n",
      "Model accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Set the training data\n",
    "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_train = np.array([0, 1, 1, 0])\n",
    "\n",
    "# create the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(units=1, input_dim=2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the GPU\n",
    "with tf.device('/GPU:0'):\n",
    "    model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "# rate the model\n",
    "accuracy = model.evaluate(X_train, y_train)[1]\n",
    "print(f'Model accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b0713a-ae86-40ff-b8b5-67c6584b643d",
   "metadata": {},
   "source": [
    "### ⊗ **Pytorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2bcf97-c2cb-486f-8f26-def566ae4b9b",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "PyTorch is an open source machine learning library known for its flexibility and ease of use, making it a popular choice among deep learning researchers and developers. Let's see the same code we did in tensorflow + keras only now with Pytorch.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59402a2-4733-47b2-ae15-df9a1a870e07",
   "metadata": {},
   "source": [
    "####  **Checking GPU availability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c189b174-bee5-4270-b3cf-3ed4d90411df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "\n",
    "    # Display information about available GPUs\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2972da-3852-4a28-b8f4-34a593cd5bf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "####  **Creating a neural network with Pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baefb205-d9ab-4d27-8ed0-07e5ae3d4582",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define training data as tensors\n",
    "X_train = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y_train = torch.tensor([0, 1, 1, 0], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# create the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Moving model and data to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# train the model\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# rate the model\n",
    "with torch.no_grad():\n",
    "    predicted = model(X_train)\n",
    "    predicted = (predicted > 0.5).float()\n",
    "    accuracy = (predicted == y_train).sum().item() / len(y_train)\n",
    "    print(f'Model accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8f158-6d94-447b-844e-71e3307be024",
   "metadata": {
    "id": "BMvo8TG2WWZE"
   },
   "source": [
    "##  ☆ Challenge: Zoo breakout!☆ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52bfc0f-feac-431e-8365-7ac4dfbb0135",
   "metadata": {},
   "source": [
    "Recently, there was an unexpected incident at the local zoo, **Orange Grove Zoo**: all the animals escaped from their enclosures and are now roaming freely in the zoo. To deal with this situation, we need your help to locate and classify the escaped animals, distinguishing each animal class and identifying possible vehicles that may be in the same environment.\n",
    "\n",
    "You have been assigned as the person responsible for developing a computer vision system capable of identifying and classifying the escaped animals, as well as identifying the presence of vehicles in the images. For this challenge, we will use the CIFAR-10 dataset and the PyTorch library to train a deep learning model.\n",
    "\n",
    "CIFAR-10 and CIFAR-100 datasets provide a comprehensive collection of 32x32 pixel images, grouped into 10 and 100 distinct classes, respectively.\n",
    "\n",
    "- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-10 consists of 60,000 images, each belonging to one of the ten classes: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. This dataset offers a diverse set of images representing everyday objects.\n",
    "\n",
    "- [CIFAR-100 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): CIFAR-100 expands upon the CIFAR-10 concept, containing 60,000 images as well. However, it introduces a more challenging task by categorizing images into 100 classes. These classes include various subcategories such as fruits, animals, vehicles, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af1c08-6dbd-4edc-bd08-10d0b343e9c8",
   "metadata": {
    "id": "X9pJ2tDOCaN6"
   },
   "source": [
    "a) **Create** deep neural network model utilizing the PyTorch library for the classification of animals and vehicles on a CPU and on a GPU using CIFAR-10 dataset.\n",
    "\n",
    "b) **Conduct** a comparative analysis between models trained on CPU and GPU to highlight disparities in results.\n",
    "\n",
    "c) Now, use the CIFAR-100 dataset for the classification of animals and vehicles on a GPU. Would it be a good decision to use a GPU or a CPU for the training process?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eb535f-68bb-4703-bb0a-f74372dbd09c",
   "metadata": {
    "id": "8_Ch1ZPO1bIC"
   },
   "source": [
    "### ☆ Solution ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cfb4fd-335e-482b-aa1f-2e2dd5cdc26e",
   "metadata": {},
   "source": [
    "#### CIFA-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ffce26-3d51-4b0d-8044-49b829f115e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CPU solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1cb8f-ab67-49b8-96e5-69802ce692b1",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bdd67f-de47-4431-9da4-2471925c830e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style='text-align: justify;'>\n",
    "In this notebook we have shown: \n",
    "\n",
    "- The definitios about HPC applied in AI applications;\n",
    "- Parallel computing concepts;\n",
    "- Some HPC uses cases, and solutions for AI using Tensorflow + Keras and Pytorch.\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4cbf28-b270-4cc3-b8dd-d6e8f9962c5e",
   "metadata": {},
   "source": [
    "## Clear the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff4e3e-b023-44b5-8b0f-91c6553bed72",
   "metadata": {},
   "source": [
    "Before moving on, please execute the following cell to clear up the CPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c73882cd-c157-4608-83fc-07491c5a8223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import IPython\n",
    "#app = IPython.Application.instance()\n",
    "#app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8df02-d305-49f3-a5f4-8120c990b27f",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1317d6bd-a969-407e-a991-cd38f5861c3e",
   "metadata": {},
   "source": [
    "In this section you learned the meaning of HPC applied in AI applications, and how we can use the processing speed of a GPU to improve the performance of our artificial intelligence algorithms. In the next notebook we will study HPC as solutions for AI using the tool call [_02-hpc-simulations-tensorflow.ipynb_](02-hpc-simulations-tensorflow.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gMnY4ESvfEA"
   },
   "source": [
    "# Multilayer Perceptron Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wHXE1ij1bIA"
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZLVbMKZ1bIA"
   },
   "source": [
    "* **Understand** the concept of Regression,\n",
    "* **Learn and Explore** about the mathematical principles behind Regression Problems,\n",
    "* **Create** a algorithm to for Regression Problems,\n",
    "* **Observe** the performance of the algorithm trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmwBTXpn1bIA"
   },
   "source": [
    "## The Problem: Predict Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vP0wr4R51bIA"
   },
   "source": [
    "<p style='text-align: justify;'> \n",
    "So far, we have used all the knowledge of artificial intelligence solely for classification problems. Based on one or more variables, it is possible to classify an item into class $X$, $Y$, or $Z$.\n",
    "\n",
    "However, there are other types of problems that can be solved with the knowledge that artificial intelligence provides, such as regression problems. These are prediction problems characterized by situations where we need to forecast a value based on predefined variables, such as predicting wind speed based on air humidity or the value of a health insurance plan based on the age of beneficiary.\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ4Teb2m1bIA"
   },
   "source": [
    "## The Solution: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ST3ronAy1bIA"
   },
   "source": [
    "<p style='text-align: justify;'> \n",
    "Regression is a powerful statistical technique employed to model the association between a dependent variable ($Y$) and one or more independent variables ($X$). The primary objective is to discern the optimal line that succinctly encapsulates this relationship, paving the way for reliable predictions or inferences.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'> \n",
    "Linear regression is primarily bifurcated into two types: simple and multiple linear regression. Simple linear regression deals with a single independent variable, whereas multiple linear regression accommodates two or more independent variables.\n",
    "</p> \n",
    "\n",
    "<p style='text-align: justify;'> \n",
    "The essence of the linear regression function lies in the Mean Squared Error (MSE); it quantifies the discrepancy between the data points and the line generated by the model. The calculation of MSE involves extracting the predicted values from the regression model, subtracting the corresponding actual values, squaring these differences, summing them up, and finally dividing by the total number of data points. The resultant figure, the average squared difference, provides an indication of the proficiency of model in data fitting. Upon achieving a satisfactory fit, the linear regression model can then forecast Y values for new $X$ values that were not part of the original dataset.\n",
    "</p> \n",
    "\n",
    "<p style='text-align: justify;'> \n",
    "While powerful, the regression model may falter in efficiency if the relationship between the variables deviates from a strict proportionality, as is the case in a linear function. This limitation emanates from the simplistic of method nature and its dependence on a strictly linear correlation between the variables. But what if the relationship between our variables is not linear? And what if we are dealing with more variables? The MLP brings to the table the capacity to predict values in more convoluted scenarios that are not necessarily linear, thus expanding the realm of predictive modelling.\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMvo8TG2WWZE"
   },
   "source": [
    "## ☆ Challenge #1 (Linear): Orange Weight Prediction ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTnSmI0SXYpm"
   },
   "source": [
    "<p style='text-align: justify;'> \n",
    "Suppose you are studying the relationship between the weight of oranges and their diameter. You collected data from different oranges, measuring their weight in grams and diameter in centimeters. Now, you want to use linear regression to predict the weight of an orange based on its diameter.\n",
    "</p>  \n",
    "\n",
    "| Diameter (cm) | Weight (g) |\n",
    "| :-:          | :-:      |\n",
    "|     6        |    120   |\n",
    "|     7        |    160   |\n",
    "|     8        |    170   |\n",
    "|     9        |    200   |\n",
    "|    10        |    230   |\n",
    "|    11        |    270   |\n",
    "|    12        |    270   |\n",
    "|    13        |    320   |\n",
    "|    14        |    360   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_Ch1ZPO1bIC"
   },
   "source": [
    "### ☆ Solution ☆ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEiIijxCTq5u"
   },
   "source": [
    "<p style='text-align: justify;'> \n",
    "First, given two arrays that describe the behavior of the variables, let's first plot the graph to better visualize the data.\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "DUq3CYzWQ_ga",
    "outputId": "b84ac9c9-c28d-4aaf-d422-68a1ba1bb6b3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training data\n",
    "x_train = np.array([6, 7, 8, 9, 10, 11, 12, 13, 14])              # Diameter\n",
    "y_train = np.array([120, 160, 170, 200, 230, 270, 270, 320, 360]) # Weight\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.xlabel('Diameter')\n",
    "plt.ylabel('Weight')\n",
    "plt.title('Linear Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DOyD98WVC8C"
   },
   "source": [
    "<p style='text-align: justify;'> \n",
    "\n",
    "Observing the generated graph, it is noticeable that there is a linear behavior as the variables vary. To estimate the line that describes its behavior and predict the values of X, it is necessary to perform a linear regression.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26FO3DVJO1q2",
    "outputId": "9df65104-3b9a-493b-a7b6-f58268cf379c"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the regression line\n",
    "def linear_regression(x, y):\n",
    "    n = len(x)\n",
    "    sum_x = np.sum(x)\n",
    "    sum_y = np.sum(y)\n",
    "    sum_xy = np.sum(x * y)\n",
    "    sum_x_squared = np.sum(x**2)\n",
    "\n",
    "    # Regression Coeficients\n",
    "    slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x_squared - sum_x**2)\n",
    "    intercept = (sum_y - slope * sum_x) / n\n",
    "\n",
    "    return slope, intercept \n",
    "\n",
    "def predict(x, slope, intercept):\n",
    "    return slope * x + intercept\n",
    "\n",
    "# Performs linear regression\n",
    "slope, intercept = linear_regression(x_train, y_train)\n",
    "\n",
    "# Makes a prediction for a new value\n",
    "\n",
    "x_new = 5\n",
    "y_new = predict(x_new, slope, intercept)\n",
    "\n",
    "print(f\"The prediction for x={x_new} is y={y_new}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycB46AZpVEqW"
   },
   "source": [
    "<p style='text-align: justify;'> \n",
    "\n",
    "Next, we can use the slope  and the intercept value of the linear function to plot the graph of the samples again, this time with the line that best describes their behavior.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "am4p8dH1TZD1",
    "outputId": "7667f777-11a8-4210-9b48-6c8f39adc195"
   },
   "outputs": [],
   "source": [
    "# Calculate linear regression line\n",
    "regression_line = slope * x_train + intercept\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x_train, regression_line, color='orange')\n",
    "plt.xlabel('Diameter')\n",
    "plt.ylabel('Weight')\n",
    "plt.title('Linear Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5cLL8GS1bIC",
    "tags": []
   },
   "source": [
    "##### Discussion: What happened?\n",
    "\n",
    "- ``How did the algorithm predicted the X value?``\n",
    "     \n",
    "- ``Did the plotted line on the graph match the behavior of the points?``\n",
    "\n",
    "- `` Would this solution be the same, if tha data does not have a linear pattern?``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgjxztHQN_vy"
   },
   "source": [
    "## ☆ Challenge #2(Non Linear): Orange Weight Prediction ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ksAl8ZdO6ce"
   },
   "source": [
    "<p style='text-align: justify;'> \n",
    "A farmer is interested in predicting the weight of oranges based on their characteristics. He has collected a dataset that includes the diameter, color, and texture of the peel of each orange, along with the corresponding weight. The goal is to develop a regression model using a perceptron to predict the weight of oranges based on these characteristics. The collected features are as follows:\n",
    "\n",
    "- **Diameter**: the diameter of the orange in centimeters. </br>\n",
    "\n",
    "- **Color**: a measure of the color of the orange on a scale from $0$ to $1$, where $0$ represents green oranges and $1$ represents ripe oranges.</br>\n",
    "\n",
    "- **Texture**: a measure of the texture of the orange peel on a scale from $0$ to $1$, where $0$ represents smooth peel and $1$ represents rough peel.</br>\n",
    "\n",
    "The weight of the oranges has been measured in grams and is the output variable that we want to predict. Your goal as a data scientist is to train a regression perceptron using the collected data to make accurate predictions of the weight of oranges based on the features of diameter, color, and texture. Here is the data colected:\n",
    "</p>\n",
    "\n",
    "| Diameter (cm) | Color | Texture | Weight (g) |\n",
    "| :-:           | :-:   | :-:     | :-:      |\n",
    "| 7.6           | 0.4   | 0.3     | 130      |\n",
    "| 7.9           | 0.2   | 0.1     | 145      |\n",
    "| 6.8           | 0.6   | 0.4     | 110      |\n",
    "| 6.4           | 0.5   | 0.2     | 95       |\n",
    "| 8.2           | 0.3   | 0.5     | 160      |\n",
    "| 7.2           | 0.4   | 0.3     | 120      |\n",
    "| 6.6           | 0.2   | 0.2     | 100      |\n",
    "| 7.1           | 0.3   | 0.4     | 135      |\n",
    "| 6.9           | 0.5   | 0.1     | 115      |\n",
    "| 8.0           | 0.6   | 0.3     | 150      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JM-ZLKpYPYvh"
   },
   "source": [
    "### ☆ Solution ☆ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the graphs of the relationship between weight and each dependent variable, we can see that they do not necessarily have a linear relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data from the table\n",
    "diameter = [7.6, 7.9, 6.8, 6.4, 8.2, 7.2, 6.6, 7.1, 6.9, 8.0]\n",
    "color = [0.4, 0.2, 0.6, 0.5, 0.3, 0.4, 0.2, 0.3, 0.5, 0.6]\n",
    "texture = [0.3, 0.1, 0.4, 0.2, 0.5, 0.3, 0.2, 0.4, 0.1, 0.3]\n",
    "weight = [130, 145, 110, 95, 160, 120, 100, 135, 115, 150]\n",
    "\n",
    "# Plotting the graphs\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Graph of weight against diameter\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(diameter, weight, color='orange')\n",
    "plt.xlabel('Diameter (cm)')\n",
    "plt.ylabel('Weight (g)')\n",
    "plt.title('Weight vs Diameter')\n",
    "\n",
    "# Graph of weight against color\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(color, weight, color='orange')\n",
    "plt.xlabel('Color')\n",
    "plt.ylabel('Weight (g)')\n",
    "plt.title('Weight vs Color')\n",
    "\n",
    "# Graph of weight against texture\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(texture, weight,  color='orange')\n",
    "plt.xlabel('Texture')\n",
    "plt.ylabel('Weight (g)')\n",
    "plt.title('Weight vs Texture')\n",
    "\n",
    "# Displaying the graphs\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, in this case, a linear regression model will not solve the problem efficiently. Instead, we built a neural network to predict the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPqW66s1iuyE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MultilayerPerceptron:\n",
    "    def __init__(self, num_inputs, hidden_layers, num_outputs):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.num_outputs = num_outputs\n",
    "        self.weights = self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        weights = []\n",
    "        layer_sizes = [self.num_inputs] + self.hidden_layers + [self.num_outputs]\n",
    "\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            layer_weights = np.random.randn(layer_sizes[i], layer_sizes[i-1])\n",
    "            weights.append(layer_weights)\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _forward_pass(self, X):\n",
    "        activations = [X]\n",
    "\n",
    "        for i in range(len(self.weights)):\n",
    "            current_activation = self._sigmoid(np.dot(activations[i], self.weights[i].T))\n",
    "            activations.append(current_activation)\n",
    "\n",
    "        return activations\n",
    "\n",
    "    def _backward_pass(self, X, y, activations, learning_rate):\n",
    "        num_examples = X.shape[0]\n",
    "        delta = activations[-1] - y.reshape(-1, self.num_outputs)\n",
    "\n",
    "        for i in range(len(self.weights)-1, -1, -1):\n",
    "            weight_gradients = np.dot(delta.T, activations[i])\n",
    "            self.weights[i] -= (learning_rate / num_examples) * weight_gradients\n",
    "\n",
    "            delta = np.dot(delta, self.weights[i]) * (activations[i] * (1 - activations[i]))\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            activations = self._forward_pass(X)\n",
    "            self._backward_pass(X, y, activations, learning_rate)\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations = self._forward_pass(X)\n",
    "        return activations[-1].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTiupIiYi0IM"
   },
   "source": [
    "<p style='text-align: justify;'>\n",
    "After build the MLP, its time to input the data, and train the model, so we can aply in other cases:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MpxaQIisQUqW",
    "outputId": "7799e50f-0eed-4a6c-afb2-9b29410b7a57"
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "X = np.array([[7.6, 0.4, 0.3],\n",
    "              [7.9, 0.2, 0.1],\n",
    "              [6.8, 0.6, 0.4],\n",
    "              [6.4, 0.5, 0.2],\n",
    "              [8.2, 0.3, 0.5],\n",
    "              [7.2, 0.4, 0.3],\n",
    "              [6.6, 0.2, 0.2],\n",
    "              [7.1, 0.3, 0.4],\n",
    "              [6.9, 0.5, 0.1],\n",
    "              [8.0, 0.6, 0.3]])\n",
    "\n",
    "y = np.array([130, 145, 110, 95, 160, 120, 100, 135, 115, 150])\n",
    "\n",
    "# Data normalization\n",
    "X_normalized = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "y_normalized = (y - np.mean(y)) / np.std(y)\n",
    "\n",
    "# Create an instance of Multilayer Perceptron\n",
    "mlp = MultilayerPerceptron(num_inputs=3, hidden_layers=[4, 4], num_outputs=1)\n",
    "\n",
    "# Train the model\n",
    "mlp.train(X_normalized, y_normalized, epochs=100, learning_rate=0.1)\n",
    "\n",
    "# Test data\n",
    "X_test = np.array([[7.8, 0.4, 0.2],\n",
    "                   [6.7, 0.3, 0.3],\n",
    "                   [7.0, 0.6, 0.5]])\n",
    "\n",
    "# Normalize the test data\n",
    "X_test_normalized = (X_test - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# Make predictions for the test data\n",
    "predictions_normalized = mlp.predict(X_test_normalized)\n",
    "\n",
    "# Denormalize the output predictions\n",
    "predictions = (predictions_normalized * np.std(y)) + np.mean(y)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Orange {}: Predicted Weight: {:.2f}g\".format(i+1, predictions[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceYMSHgFifia",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Discussion: What happened?\n",
    "\n",
    "- ``How did the algorithm predicted the orange weights?``\n",
    "     \n",
    "- ``Would the last model we would be able to predict the values? Why?``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ☆ Challenge #3: Wind Speed Prediction ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "\n",
    "Wind speed is an important factor that can affect the growth and yield of oranges. The farmer has collected historical data on wind speed and its corresponding suitability for orange cultivation. Each sample consists of a measurement of wind speed (in meters per second), which is available in _datasets_ folder, named as \"wind_data_train.csv\".\n",
    "\n",
    "In order to ensure ideal growth conditions, the same farmer wishes to develop a prediction system that determines the wind speed based on the historical data.\n",
    "\n",
    "You are tasked with training the model using the provided data and then testing it using a separate test dataset, named \"wind_data_test.csv\" and located at _datasets_ directory.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☆ Solution ☆ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "First, we need to read and process the input files. Remember that what will be predicted is the wind speed at $10$ meters (ws_10), so $y$ should have the last row, and $x$ should not have the last row.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input file:\n",
    "x_train = pd.read_csv(\"./datasets/wind_data_train.csv\", sep=\",\", header=0)\n",
    "\n",
    "values_title = list(x_train.columns.values)\n",
    "\n",
    "y_train = x_train.iloc[:, [-1]]\n",
    "x_train = x_train.iloc[:, [*range(len(values_title)-1)]]\n",
    "\n",
    "x_test = pd.read_csv(\"./datasets/wind_data_test.csv\", sep=\",\", header=0)\n",
    "\n",
    "y_test = x_test.iloc[:, [-1]]\n",
    "x_test = x_test.iloc[:, [*range(len(values_title)-1)]]\n",
    "\n",
    "\n",
    "# Show data:\n",
    "print(\"----------train data info------------\")\n",
    "print(x_train.info())\n",
    "print(x_train.head())\n",
    "print(y_train.head())\n",
    "\n",
    "print(\"----------test  data info------------\")\n",
    "print(x_test.info())\n",
    "print(x_test.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "Plot data:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "\n",
    "Process data:\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the commented code to np, it automatically normalizes between 0 and 1:\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Check normalization:\n",
    "x_train = x_train/2015\n",
    "x_test = x_test/2015\n",
    "\n",
    "print(\"----------NAN in xtrain------------\")\n",
    "print(np.argwhere(np.isnan(x_train)))\n",
    "print(\"----------NAN in ytrain------------\")\n",
    "print(np.argwhere(np.isnan(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "\n",
    "Creating a function to plot graphs.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_comp(title,data_plot1,data_plot2):\n",
    "    plt.figure(figsize=(14, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "    # plt.subplot(2, 1, 0)\n",
    "    plt.plot(data_plot1,label=\"Original\")\n",
    "    plt.plot(data_plot2,label=\"Predicted\")\n",
    "\n",
    "    plt.xlabel(\"Minutes\")\n",
    "    plt.ylabel(\"Wind Speed\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "\n",
    "Afterward, we create functions for building and reading the network based on TensorFlow.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test, listall, name):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(len(x_train[0]), input_shape=(len(x_train[0]),), activation=tf.nn.tanh))\n",
    "    model.add(tf.keras.layers.Dense(90, activation=tf.nn.tanh))\n",
    "    model.add(tf.keras.layers.Dense(90, activation=tf.nn.tanh))\n",
    "    model.add(tf.keras.layers.Dense(90, activation=tf.nn.tanh))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "    tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "                    loss=['mse'],\n",
    "                    metrics=['mae'])\n",
    "\n",
    "    print(\"training learning_rate=%f\" % learning_rate)\n",
    "    history = model.fit(x_train, y_train, batch_size=50, epochs=30)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "    print(\"MSE:\", val_loss, \"|MAE:\", val_acc)\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.figure(figsize=(14, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Model loss Final Loss %f (MSE):%.2f MAE:%.2f' % (learning_rate, val_loss, val_acc))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "    if name != False:\n",
    "        model_json = model.to_json()\n",
    "        with open(\"%s.json\" % (name), \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # Serialize weights to HDF5\n",
    "        model.save_weights(\"%s.h5\" % (name))\n",
    "        print(\"Saved model to disk\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name):\n",
    "    # Load JSON and create model\n",
    "    json_file = open(\"%s.json\" % name, \"r\")\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    # Load weights into the new model\n",
    "    loaded_model.load_weights(\"%s.h5\" % name)\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x_train, y_train, x_test, y_test, listall, name):\n",
    "    my_file = Path(\"%s.json\" % (name))\n",
    "    if my_file.is_file():\n",
    "        return load_model(name)\n",
    "    return create_model(x_train, y_train, x_test, y_test, listall, name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "\n",
    "Training the network (or loading if one exists with the name specified within \"quotation marks\").\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input and Outpus number\n",
    "listsee = [0]\n",
    "listall = [9]\n",
    "\n",
    "model = get_model(x_train, y_train, x_test, y_test, listall, \"temp2015_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "\n",
    "Using the network to predict the data using the training dataset.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "for i in listsee:\n",
    "    plot_data_comp(\"Comparation %s: Anemometer vs. Predicted: Dataset = TRAIN\" % (values_title[9]),y_test[:,i],\n",
    "                   predictions[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilcR9NWJ1bIC"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCCcZ7Q31bIC"
   },
   "source": [
    "<p style='text-align: justify;'>\n",
    "In this notebook, we learned the concept of regression in an approach to a new problem: predicting values based on a pattern. We also applied all the concepts in practice, in two simple data analysis problem.  Despite its limitations, the linear regression model is highly effective in predicting values for proportional systems. To surpass linear regression model, we can use MultiLayer Perceptron to predict values in non linear models with a large number of variables precisely.</br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FolLqE_1bID"
   },
   "source": [
    "## Clear the Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXiePpX31bID"
   },
   "source": [
    "Before moving on, please execute the following cell to clear up the CPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMB90WpX1bID",
    "outputId": "1df63f58-1161-495d-c481-2713ff31a7fa"
   },
   "outputs": [],
   "source": [
    "#import IPython\n",
    "#app = IPython.Application.instance()\n",
    "#app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbgrxWUP1bIE"
   },
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RniCDPdQ1bIE"
   },
   "source": [
    "Congratulations, you have completed second part the learning objectives of the course! As a final exercise, successfully complete an applied problem in the assessment in [_04-multilayer-assessment.ipynb_](04-multilayer-assessment.ipynb)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

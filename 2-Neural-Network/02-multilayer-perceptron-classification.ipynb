{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multilayer Perceptron Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "In this section we will study the concepts behind the classification problem in a MLP using Backpropagation.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Understand** how classification works in a MLP;\n",
    "* **Learn** how to classify images with a MLP;\n",
    "* **Explore** the different ways to classify images;\n",
    "* **Create** classification MLP with backpropagation;\n",
    "* **Train** the Multilayer Perceptron Network using Backpropagation to classify images;\n",
    "* **Observe** how the MLP classify the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem: Classifying images in the Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "Classifying images using an MLP is extremely common across various technology fields nowadays. However, to achieve high accuracy, it is necessary to implement image classification using backpropagation algorithms in an MLP (Multilayer Perceptron).\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Solution: Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "Backpropagation is essential in MLPs for efficient error propagation, weight adjustment, and learning of non-linear relationships. It allows the network to iteratively update the weights based on gradients, resulting in improved performance and generalization to unseen data.\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Backpropagation works in a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "The Backpropagation is based on gradient descent, which aims to minimize the error between the network's predicted output and the target output. The backpropagation algorithm efficiently computes the gradient of the error function for the network's weights, allowing for iterative adjustment of the weights to minimize the error.\n",
    "\n",
    "The key idea behind Backpropagation is to propagate the error from the output of the network layer back to its input layer. This process involves two main steps: forward propagation and backward propagation.\n",
    "    \n",
    "1. <b>Forward Propagation:</b>\n",
    "During forward propagation, the input data is fed into the network, and the activations of each neuron are computed layer by layer until reaching the output layer. The activations are obtained by applying an activation function (such as sigmoid or ReLU) to each neuron's weighted sum of inputs.\n",
    "    \n",
    "2. <b>Backward Propagation:</b>\n",
    "Once the output activations of a layer are computed, the error between the predicted output and the target output is calculated using an error function (e.g., mean squared error or cross-entropy). Then, the algorithm propagates this error back through the network to update the weights.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Weights and Bias in the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "In a neural network, the weights and biases are updated during training to optimize the network's performance. The backpropagation algorithm is commonly used to calculate the gradients of the weights and biases, which are then used to update their values. \n",
    "\n",
    "The main steps involved in the backward propagation are as follows:\n",
    "\n",
    "1.  <b>Error Calculation:</b>\n",
    "    The error is calculated by taking the derivative of the error function for the output layer's activations. This derivative represents how much each output activation contributes to the overall error.\n",
    "    \n",
    "2.  <b>Gradient Calculation:</b>\n",
    "    The derivative of the error function for the weights of each neuron is computed. This is done by applying the chain rule, which allows the calculation of the result of a composite function. The gradient is calculated for each layer, starting from the output layer and moving backward. \n",
    "\n",
    "3.  <b>Weight Update:</b>\n",
    "    The calculated gradients are then used to update the weights of the network. The weights are adjusted in the direction that minimizes the error based on the computed gradients and a learning rate parameter. The learning rate determines the step size taken during weight updates. \n",
    "    \n",
    "4.  <b>Repeat:</b>\n",
    "    Steps 2a to 2c are repeated for multiple iterations or until a stopping criterion is met (e.g., a predefined maximum number of iterations or reaching a satisfactory error level).\n",
    "\n",
    "The backpropagation algorithm enables the network to learn the appropriate weights for making accurate predictions by iteratively adjusting the weights through forward and backward propagation. Updating the weights based on error gradients allows the network to improve its performance gradually.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3VsmcZU4O8I"
   },
   "source": [
    "## ☆ Challenger: Image Classification ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will train an MLP to sort handwritten number images. The dataset used is [_MNIST_](https://en.wikipedia.org/wiki/MNIST_database), which consists of 16x16 pixels grayscale images of handwritten digits. Each image is represented as a vector of 256-pixel values, and each image is labeled with the digit it means (0 to 9). You must use an input layer with 256 neurons (to represent the image pixels), at least one hidden layer with the number you choose, and an output layer with ten neurons (one for each digit). Your goal is to train an MLP to sort these numbers correctly. Use the sigmoid activation function on all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "<img src=\"./images/mnist1.png\" style=\"width: 600px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ Import Python Packages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let is start by importing all the modules we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6294,
     "status": "ok",
     "timestamp": 1685370286877,
     "user": {
      "displayName": "Murilo Boratto",
      "userId": "13998345321799991370"
     },
     "user_tz": 180
    },
    "id": "CHadwpvmREvE"
   },
   "outputs": [],
   "source": [
    "import torch                       # for general PyTorch functionality\n",
    "import torch.nn as nn              # for functional for neural network based functions\n",
    "import torch.nn.functional as F    # for functional for neural network based functions\n",
    "import torch.optim as optim        # for our optimizer which will update the parameters of our neural network\n",
    "import torch.utils.data as data    # for handling the dataset\n",
    "\n",
    "import torchvision.transforms as transforms # for data augmentation\n",
    "import torchvision.datasets as datasets     # for loading the dataset\n",
    "\n",
    "from sklearn import metrics                 # for visualizing a confusion matrix\n",
    "from sklearn import decomposition           # for visualizing the neural network's representations in two dimensions\n",
    "from sklearn import manifold                # for visualizing the neural network's representations in two dimensions  \n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt             # for plotting\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main ones we need to import are:\n",
    "\n",
    "- The **torch** module is part of [_PyTorch_](https://pytorch.org), a popular machine learning library in Python.\n",
    "\n",
    "- The **torchvision** is a package that provides access to popular datasets, model architectures, and image transformations for computer vision. It is generally used alongside PyTorch.\n",
    "\n",
    "- The **sklearn** module is part of the [_Scikit-learn_](https://scikit-learn.org/stable/) package that is a powerful and widely used library in Python for machine learning. It provides a range of supervised and unsupervised learning algorithms in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFMp16oI4O8N"
   },
   "source": [
    "To ensure we get reproducible results we set the random seed for Python, Numpy and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1685370428778,
     "user": {
      "displayName": "Murilo Boratto",
      "userId": "13998345321799991370"
     },
     "user_tz": 180
    },
    "id": "rvBiLgLAREvN"
   },
   "outputs": [],
   "source": [
    "SEED = 12345\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDMpvXwB4O8Q"
   },
   "source": [
    "The first thing we will do is load our dataset. This will automatically download the training set for the [_MNIST dataset_](https://en.wikipedia.org/wiki/MNIST_database).  This is a dataset of 28x28 black and white images consisting of handwritten digits, 0 to 9.  We will save it in a folder called `.data`. It will create the folder if it does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "<img src=\"./images/mlp-mnist.png\" style=\"width: 500px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1685370433113,
     "user": {
      "displayName": "Murilo Boratto",
      "userId": "13998345321799991370"
     },
     "user_tz": 180
    },
    "id": "UOIQVy-cREvQ",
    "outputId": "84a9526c-0d4b-4a63-c97d-c5be834666df"
   },
   "outputs": [],
   "source": [
    "ROOT = '.data'\n",
    "\n",
    "train_data = datasets.MNIST(root=ROOT,\n",
    "                            train=True,\n",
    "                            download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ Normalize the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMThB8Vs4O8V"
   },
   "source": [
    "<p style='text-align: justify;'> \n",
    "Next, we want to normalize our data. This means we want it to have a mean of zero and a standard deviation of one.  We normalize our data by subtracting the mean and dividing by the standard deviation of our dataset. First, we need to calculate the mean and standard deviation.  To calculate the means and standard deviations we get the actual data (the images) using the `.data.` attribute of our training data, convert them into floating point numbers, and then use the built-in `mean` and `std` functions to calculate the mean and standard deviation, respectively. The image data has values between 0-255, which we want to scale between 0-1, so we divide by 255.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhM076c7Zzrv"
   },
   "outputs": [],
   "source": [
    "mean = train_data.data.float().mean() / 255\n",
    "std = train_data.data.float().std() / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "wCjRlfI9aMMl",
    "outputId": "36330593-f600-4cc8-8851-986fe709bfe0"
   },
   "outputs": [],
   "source": [
    "print(f'Value of calculated mean: {mean}')\n",
    "print(f'Value of calculated std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ Data augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U50VOMAW4O8d"
   },
   "source": [
    "After calculated our mean and standard deviation we use Torchvision's `transforms`.  A `transform` states how our data should be augmented and processed. Data augmentation involves manipulating the available training data in a way that artificially creates more training examples. We use `transforms.Compose` to built a list of transformations that will be applied to the image. \n",
    "\n",
    "The transforms we use are:\n",
    "- `RandomRotation` - randomly rotates the image between `(-x, +x)` degrees, where we have set `x = 5`. Note, the `fill=(0,)` is due to a [bug](https://github.com/pytorch/vision/issues/1759) in some versions of torchvision. \n",
    "\n",
    "- `RandomCrop` - this first adds `padding` around our image, 2 pixels here, to artificially make it bigger, before taking a random `28x28` square crop of the image.\n",
    "\n",
    "- `ToTensor()` - this converts the image from a PIL image into a PyTorch tensor.\n",
    "\n",
    "- `Normalize` - this subtracts the mean and divides by the standard deviations given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WuYq4cRdREvV"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                       transforms.RandomRotation(5, fill=(0,)),\n",
    "                                       transforms.RandomCrop(28, padding=2),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[mean], std=[std])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[mean], std=[std])\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ Train and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73S5zyox4O8h"
   },
   "source": [
    "Now we have defined our transforms we can then load the train and test data with the relevant transforms defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPvVD4VLREva"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root=ROOT,\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform=train_transforms)\n",
    "\n",
    "test_data = datasets.MNIST(root=ROOT,\n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayyHLZjg4O8o"
   },
   "source": [
    "We can simply check the `len` of the datasets to see how many examples are within each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "fPo3pfgciRo3",
    "outputId": "ae4c193d-f5a8-491b-89c7-ebf9fd456312"
   },
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ Plot Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a23Msn44O8u"
   },
   "source": [
    "We can look at some images within our dataset to see what we're working with. The function below plots a square grid of images. If you supply less than a square number of images, it will ignore the last few. We will load 25 images, which have been processed through our transforms so that they will be randomly rotated and cropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2IUyQZcaWh6"
   },
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        ax.imshow(images[i].view(28, 28).cpu().numpy(), cmap='bone')\n",
    "        ax.axis('off')\n",
    "        \n",
    "N_IMAGES = 25\n",
    "\n",
    "images = [image for image, label in [train_data[i] for i in range(N_IMAGES)]]\n",
    "\n",
    "plot_images(images)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDgsLY3k4O87"
   },
   "source": [
    "The MNIST dataset comes with a training and test set, but not a validation set. We want to use a validation set to check how well our model performs on unseen data. Furthermore, we create a validation set, taking 10% of the training set. First, we have to define the exact number of examples that we want to be in each split of the training/validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QI6JckYREve"
   },
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be4vqf484O9A"
   },
   "source": [
    "Then, we use the `random_split` function to take a random 10% of the training set to use as a validation set. The remaining 90% will stay as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yVJvPZ-RVvI"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = data.random_split(train_data,\n",
    "                                           [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8DYs4UE4O9E"
   },
   "source": [
    "We can print out the number of examples again to check our splits are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "tBhHj9uaREvi",
    "outputId": "4f5089ea-f796-43be-a9a6-250bcdd009f7"
   },
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DDXVins4O9K"
   },
   "source": [
    "One thing to consider is that as the validation set has been created from the training set it has the same transforms as the training set, with the random rotating and cropping. As we want our validation set to act as a proxy for the test set, it should also be fixed, without any random augmentation.  First, let is see what 25 of the images within the validation set look like with the training transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "ILxnxJnketAQ",
    "outputId": "397b4746-43ca-4eb4-d803-22b19806d62e"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 25\n",
    "\n",
    "images = [image for image, label in [valid_data[i] for i in range(N_IMAGES)]]\n",
    "\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiHKHzLW4O9O"
   },
   "source": [
    "We can now simply replace the validation set's transform by overwriting it with our test transforms from above.\n",
    "\n",
    "As the validation set is a `Subset` of the training set, if we change the transforms of one, then by default Torchvision will change the transforms of the other. To stop this from happening, we make a `deepcopy` of the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5LZxzXGcsNk"
   },
   "outputs": [],
   "source": [
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = test_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JdganrY4O9S"
   },
   "source": [
    "To double check we've correctly replaced the training transforms, we can view the same set of images and notice how they're more central (no random cropping) and have a more standard orientation (no random rotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "tMa21luaevxU",
    "outputId": "47752555-4f37-4c67-d720-4224c42b13b7"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 25\n",
    "\n",
    "images = [image for image, label in [valid_data[i] for i in range(N_IMAGES)]]\n",
    "\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7vOeo1a4O9W"
   },
   "source": [
    "Next, we will define a `DataLoader` for each training/validation/test set. We can iterate over these, and they will yield batches of images and labels that we can use to train our model. We only need to shuffle our training set as it will be used for stochastic gradient descent, and we want each batch to be different between epochs. We aren't using the validation or test sets to update our model parameters, so they do not need to be shuffled. We want to use the most considerable batch size that we can. The 64 is relatively small and can be increased if our hardware can handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGdKSORpREvr"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = data.DataLoader(train_data,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data,\n",
    "                                batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ Defining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZuPIyvN4O9b"
   },
   "source": [
    "Our model will be a neural network, specifically a multilayer perceptron (MLP) with two hidden layers. The image below shows the archicture of the model. \n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"./images/mlp-mnist.png\" style=\"width: 500px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "Specifically, first we will flatten our 1x28x28 (1 color channel, 28 pixels height and width) image into a 784 element vector, also called 784 *features*. We flatten our input, as MLPs cannot handle two or three-dimensional data. Next, the 784 dimensional input is passed through the first hidden layer to transform it into 250 dimensions. Then, another hidden layer, which will transform it to 100 dimensions. Finally, an output layer which will transform it into a 10 dimensional vector. The output dimension should equal the number of classes within your data. Here we have ten digits, 0 - 9, so need our output to be 10 dimensions.\n",
    "\n",
    "The transformation between 784 to 250, 250 to 100 and 100 to 10 dimensions are done by `Linear` layers. These are also known as fully connected or affine layers. In these layers, every element in one layer is connected to every element in the next. We can think of these elements as *neurons*, as this architecture is inspired by how the human brain is made of millions of interconnected nodes, also called neurons. \n",
    "\n",
    "Each connection between a neuron in one layer and a neuron in the next has a *weight* associated with it. The input to one neuron is the sum of the weighted values of all neurons in the previous layer connected to it, plus a weighted bias term, where the bias value is always 1. The neuron then applies an *activation function* to this weighted sum. This activation function is a non-linear function that allows the neural network to learn non-linear functions between inputs and outputs. \n",
    "\n",
    "We define our MLP below, which consists of three linear layers. We first take the input batch of images and flatten them, so they can be passed into the linear layers. We then pass them through the first linear layer, `input_fc`, which calculates the weighted sum of the inputs, and then apply the *ReLU* (rectified linear unit) activation function elementwise. This result is then passed through another linear layer, `hidden_fc`, again applying the same activation function elementwise. Finally, we pass this through the final linear layer, `output_fc`. We return not only the output but also the second hidden layer as we will do some analysis on it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ReLU activation function** is a popular non-linear function that is simply $max(0, x)$, where $x$ is the weighted sum of the inputs to that neuron. Other activation functions used are hyperbolic tan (tanh) and sigmoid function, however ReLU is the most commonly used.\n",
    "\n",
    "One thing to note is that we do not use an activation function on the input directly or on the output. You should never use activation functions directly on the input, i.e. `F.relu(x)`. PyTorch combines activation functions to be applied on the output with the functions which calculate the *loss*, also known as *error* or *cost*, of a neural network. This is done for numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAqzcW9XREvu"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_fc = nn.Linear(input_dim, 250)\n",
    "        self.hidden_fc = nn.Linear(250, 100)\n",
    "        self.output_fc = nn.Linear(100, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        h_1 = F.relu(self.input_fc(x))\n",
    "\n",
    "        h_2 = F.relu(self.hidden_fc(h_1))\n",
    "\n",
    "        y_pred = self.output_fc(h_2)\n",
    "\n",
    "        return y_pred, h_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgPqWhK-4O9f"
   },
   "source": [
    "We will define our model by creating an instance of it and setting the correct input and output dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Ew0aobVREv0"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 28 * 28\n",
    "OUTPUT_DIM = 10\n",
    "\n",
    "model = MLP(INPUT_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3bacWHd4O9j"
   },
   "source": [
    "We can also create a small function to calculate the number of trainable parameters (weights and biases) in our model - in case all of our parameters are trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gF2fmTBREv8"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gik6Q5ZB4O9q"
   },
   "source": [
    "The first layer has 784 neurons connected to 250 neurons, so 784*250 weighted connections plus 250 bias terms.\n",
    "\n",
    "The second layer has 250 neurons connected to 100 neurons, 250*100 weighted connections plus 100 bias terms.\n",
    "\n",
    "The third layer has 100 neurons connected to 10 neurons, 100*10 weighted connections plus 10 bias terms.\n",
    "\n",
    "$$784 \\cdot 250 + 250 + 250 \\cdot 100 + 100 + 100 \\cdot 10 + 10 = 222,360$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8N1iy4Sji4jl",
    "outputId": "753725c3-7394-4254-f8ca-073dc08648ac"
   },
   "outputs": [],
   "source": [
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiL9hZqX4O9x"
   },
   "source": [
    "Next, we will define our optimizer. This is the algorithm we will use to update the parameters of our model with respect to the loss calculated on the data:\n",
    "\n",
    "- Pass a batch of data through your model,\n",
    "\n",
    "- Calculate the loss of your batch by comparing your predictions of model against the actual labels,\n",
    "\n",
    "- Calculate the gradient of each of your parameters with respect to the loss,\n",
    "\n",
    "- Update each of your parameters by subtracting their gradient multiplied by a small *learning rate* parameter.\n",
    "\n",
    "We use the *Adam* algorithm with the default parameters to update our model. Improved results could be obtained by searching over different optimizers and learning rates, however default Adam is usually a good starting off point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eC2P8WJuREv_"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBvdk2RR4O95"
   },
   "source": [
    "Then, we define a *criterion*, PyTorch's name for a loss/cost/error function. This function will take in your model's predictions with the actual labels and then compute the loss/cost/error of your model with its current parameters.\n",
    "\n",
    "`CrossEntropyLoss` both computes the *softmax* activation function on the supplied predictions as well as the actual loss via *negative log likelihood*. \n",
    "\n",
    "Briefly, the softmax function is:\n",
    "\n",
    "$$\\text{softmax }(\\mathbf{x}) = \\frac{e^{x_i}}{\\sum_j e^{x_j}}$$ \n",
    "\n",
    "This turns out 10 dimensional output, where each element is an unbounded real number, into a probability distribution over 10 elements. That is, all values are between 0 and 1, and together they all sum to 1. \n",
    "\n",
    "So we can use negative log likelihood for our loss function, as it expects probabilities. PyTorch calculates negative log likelihood for a single example via:\n",
    "\n",
    "$$\\text{negative log likelihood }(\\mathbf{\\hat{y}}, y) = -\\log \\big( \\text{softmax}(\\mathbf{\\hat{y}})[y] \\big)$$\n",
    "\n",
    "$\\mathbf{\\hat{y}}$ is the $\\mathbb{R}^{10}$ output, from our neural network, whereas $y$ is the label, an integer representing the class. The loss is the negative log of the class index of the softmax. For example:\n",
    "\n",
    "$$\\mathbf{\\hat{y}} = [5,1,1,1,1,1,1,1,1,1]$$\n",
    "\n",
    "$$\\text{softmax }(\\mathbf{\\hat{y}}) = [0.8585, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157]$$\n",
    "\n",
    "If the label was class zero, the loss would be:\n",
    "\n",
    "$$\\text{negative log likelihood }(\\mathbf{\\hat{y}}, 0) = - \\log(0.8585) = 0.153 \\dots$$\n",
    "\n",
    "If the label was class five, the loss would be:\n",
    "\n",
    "$$\\text{negative log likelihood }(\\mathbf{\\hat{y}}, 5) = - \\log(0.0157) = 4.154 \\dots$$\n",
    "\n",
    "So, intuitively, as your model's output corresponding to the correct class index increases, your loss decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OO2BL-qBREwD"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwKdgFmU4O-A"
   },
   "source": [
    "We then define `device`. This is used to place your model and data on to a GPU, if you have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QgyFD6gREwH"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzKopDSd4O-F"
   },
   "source": [
    "We place our model and criterion on to the device by using the `.to` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTvjOcbLREwM"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bd0F_7i_4O-M"
   },
   "source": [
    "Next, we'll define a function to calculate the accuracy of our model. This takes the index of the highest value for your prediction and compares it against the actual class label. We then divide how many our model got correct by the amount in the batch to calculate accuracy across the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkttGrmkREwP"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3T0oPWh4O-R"
   },
   "source": [
    "We finally define our training loop.This will:\n",
    "\n",
    "- Put our model into `train` mode,\n",
    "- Iterate over our dataloader, returning batches of (image, label),\n",
    "- Place the batch on to our GPU, if we have one,\n",
    "- Clear the gradients calculated from the last batch,\n",
    "- Pass our batch of images, `x`, through to model to get predictions, `y_pred`,\n",
    "- Calculate the loss between our predictions and the actual labels,\n",
    "- Calculate the accuracy between our predictions and the actual labels,\n",
    "- Calculate the gradients of each parameter,\n",
    "- Update the parameters by taking an optimizer step,\n",
    "- Update our metrics.\n",
    "\n",
    "Some layers act differently when training and evaluating the model that contains them, hence why we must tell our model we are in \"training\" mode. The model we are using here does not use any of those layers, however it is good practice to get used to putting your model in training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kCtKBMfREwS"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, _ = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kuF4-Cx4O-X"
   },
   "source": [
    "The evaluation loop is similar to the training loop. The differences are:\n",
    "- we put our model into evaluation mode with `model.eval()`\n",
    "- we wrap the iterations inside a `with torch.no_grad()`\n",
    "- we do not zero gradients as we are not calculating any\n",
    "- we do not calculate gradients as we are not updating parameters\n",
    "- we do not take an optimizer step as we are not calculating gradients\n",
    "\n",
    "`torch.no_grad()` ensures that gradients are not calculated for whatever is inside the `with` block. As our model will not have to calculate gradients, it will be faster and use less memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XL4sRI8REwV"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dySDirym4O-c"
   },
   "source": [
    "The final step before training is to define a small function to tell us how long an epoch took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENrsvnEZREwZ"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHn-rDvA4O-h"
   },
   "source": [
    "We are finally ready to train!\n",
    "\n",
    "During each epoch we calculate the training loss and accuracy, followed by the validation loss and accuracy. We then check if the validation loss achieved is the best validation loss we have seen. If so, we save our model's parameters (called a `state_dict`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "p-gtfzafREwc",
    "outputId": "a1314661-c18c-4de6-d6f5-89541165199e"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBYcKw8Y4O-k"
   },
   "source": [
    "Afterwards, we load our the parameters of the model that achieved the best validation loss and then use this to evaluate our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGDeNGLhREwf"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUPPCMA34O-p"
   },
   "source": [
    "Our model achieves 98% accuracy on the test set.\n",
    "\n",
    "This can be improved by tweaking hyperparameters, e.g. number of layers, number of neurons per layer, optimization algorithm used, learning rate, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WrRhzovQRho5",
    "outputId": "87424d6b-9007-4b7b-d259-d05fdf040d3d"
   },
   "outputs": [],
   "source": [
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⊗ Examining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeInowvn4O-0"
   },
   "source": [
    "Now we have trained our model, there are a few things we can look at. Most of these are simple exploratory analysis, but they can offer some insights into your model. An important thing to do is check what examples your model gets wrong and ensure that they're reasonable mistakes.\n",
    "\n",
    "The function below will return the predictions of model over a given dataset. It will return the inputs (image) the outputs (model predictions) and the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cK-f6JLGNp2u"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim=-1)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    probs = torch.cat(probs, dim=0)\n",
    "\n",
    "    return images, labels, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwO_bDPTOGFG"
   },
   "source": [
    "We can then get these predictions and, by taking the index of the highest predicted probability, get the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRqKe4PNognL"
   },
   "outputs": [],
   "source": [
    "images, labels, probs = get_predictions(model, test_iterator, device)\n",
    "\n",
    "pred_labels = torch.argmax(probs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lVdWZ4gOr2R"
   },
   "source": [
    "Then, we can make a confusion matrix from our actual labels and our predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8HvTwi5qgmG"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, pred_labels):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    cm = metrics.confusion_matrix(labels, pred_labels)\n",
    "    cm = metrics.ConfusionMatrixDisplay(cm, display_labels=range(10))\n",
    "    cm.plot(values_format='d', cmap='Blues', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgBX_wx7-B4D"
   },
   "source": [
    "The results seem reasonable enough, the most confused predictions-actuals are: 3-5 and 2-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "C6gprB1sO7fy",
    "outputId": "c71d372a-8b94-4573-9239-b7b0825b2208"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgWqvvPg4O-9"
   },
   "source": [
    "Next, for each of our examples, we can check if our predicted label matches our actual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKTDsxMhvXv_"
   },
   "outputs": [],
   "source": [
    "corrects = torch.eq(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0O_8iZxPBtW"
   },
   "source": [
    "We can then loop through all of the examples over our model's predictions and store all the examples the model got incorrect into an array.\n",
    "\n",
    "Then, we sort these incorrect examples by how confident they were, with the most confident being first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAAZKuyYPCi3"
   },
   "outputs": [],
   "source": [
    "incorrect_examples = []\n",
    "\n",
    "for image, label, prob, correct in zip(images, labels, probs, corrects):\n",
    "    if not correct:\n",
    "        incorrect_examples.append((image, label, prob))\n",
    "\n",
    "incorrect_examples.sort(reverse=True, key=lambda x: torch.max(x[2], dim=0).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbq9Yjki4O_E"
   },
   "source": [
    "We can then plot the incorrectly predicted images along with how confident they were on the actual label and how confident they were at the incorrect label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDFDmbbQ1oRF"
   },
   "outputs": [],
   "source": [
    "def plot_most_incorrect(incorrect, n_images):\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        image, true_label, probs = incorrect[i]\n",
    "        true_prob = probs[true_label]\n",
    "        incorrect_prob, incorrect_label = torch.max(probs, dim=0)\n",
    "        ax.imshow(image.view(28, 28).cpu().numpy(), cmap='bone')\n",
    "        ax.set_title(f'true label: {true_label} ({true_prob:.3f})\\n'\n",
    "                     f'pred label: {incorrect_label} ({incorrect_prob:.3f})')\n",
    "        ax.axis('off')\n",
    "    fig.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNUqTyZ94O_J"
   },
   "source": [
    "Below we can see the 25 images the model got incorrect and was most confident about. A lot of these digits are irregular, so it's difficult for the model to do well on these. The images that do look fine, if you squint you can sort of see why the model got it wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "HtZG13Ui6aYT",
    "outputId": "0c02244e-43d5-4871-8397-b0b2fe7ef8c9"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 25\n",
    "\n",
    "plot_most_incorrect(incorrect_examples, N_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfZg0Y2o4PAC"
   },
   "source": [
    "### Summary\n",
    "\n",
    "In this notebook we have shown: \n",
    "\n",
    "- Loading Torchvision datasets,\n",
    "- Loading transforms to augment and normalize our data,\n",
    "- Defining a MLP,\n",
    "- Training a model to achieve > 98% accuracy,\n",
    "- Viewing our mistakes of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear the Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, please execute the following cell to clear up the CPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import IPython\n",
    "#app = IPython.Application.instance()\n",
    "#app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you learned how to apply the Multilayer Perceptron for data regression. In the notebook [_03-multilayer-percepetron-regression.ipynb_](03-multilayer-percepetron-regression.ipynb)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "https://github.com/bentrevett/pytorch-image-classification/blob/master/1_mlp.ipynb",
     "timestamp": 1685370172312
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

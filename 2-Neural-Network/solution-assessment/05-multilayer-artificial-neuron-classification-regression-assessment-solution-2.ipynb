{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='text-align: justify;'>\n",
    "    Now in this challenge we will solve the proposed problem of <a href=\"https://www.kaggle.com/competitions/titanic\">Kaggle's Titanic</a>. The task consists of processing the data, generating the model, and doing a deploy. Let's start!\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #2: Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in 1502 deaths out of 2224 passengers and crew\n",
    "</p>\n",
    "While some element of luck was involved in surviving, some groups were more likely to survive than others.\n",
    "<p style='text-align: justify;'>\n",
    "In this problem, we ask you to build a predictive model that answers the question: \"What sorts of people were more likely to survive?\" using passenger data (i.e., name, age, gender, socio-economic class, etc.).\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this competition, you will gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv`, and the other is titled `test.csv`.\n",
    "\n",
    "`train.csv` will contain the details of a subset of the passengers on board ($891$ to be exact) and, importantly, will reveal whether they survived, also known as the _ground truth_.\n",
    "\n",
    "The `test.csv` dataset contains similar information but does not disclose the _ground truth_ for each passenger. It is your job to predict these outcomes.\n",
    "\n",
    "Using the patterns in the `train.csv` data, predict whether the other $418$ passengers on board (found in `test.csv`) survived.\n",
    "\n",
    "Check out the *Data* tab to explore the datasets even further. Once you feel you have created a competitive model, please submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "\n",
    "| Variable | Definition | \tKey |\n",
    "|----------|------------|-------|\n",
    "| survival | Survival\t| 0 = No, 1 = Yes|\n",
    "| pclass   | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| sex\t   | Sex\t| |\n",
    "| Age\t   | Age in years\t| |\n",
    "| sibsp\t   | # of siblings / spouses aboard the Titanic\t| |\n",
    "| parch\t   | # of parents / children aboard the Titanic\t| |\n",
    "| ticket   | Ticket number\t| |\n",
    "| fare\t   | Passenger fare\t| |\n",
    "| cabin\t   | Cabin number\t| |\n",
    "| embarked | Port of embarkation |\tC = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "#### Variable notes\n",
    "\n",
    "**pclass**: A proxy for socio-economic status (SES)\n",
    "\n",
    "* 1st = Upper\n",
    "* 2nd = Middle\n",
    "* 3rd = Lower\n",
    "\n",
    "---\n",
    "\n",
    "**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "----\n",
    "\n",
    "**sibsp**: The dataset defines family relations in this way...\n",
    "\n",
    "* Sibling = brother, sister, stepbrother, stepsister\n",
    "* Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "----\n",
    "**parch**: The dataset defines family relations in this way...\n",
    "\n",
    "* Parent = mother, father\n",
    "* Child = daughter, son, stepdaughter, stepson\n",
    "* Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ☆ Solution problem #2 - Titanic ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Loading the training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../datasets/titanic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(f\"{path}/train.csv\", sep=\",\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_missing(train_data):    \n",
    "    for col in train_data.columns.tolist():          \n",
    "        print('{} missing data: {}'.format(col, train_data[col].isnull().sum()))\n",
    "    print('\\n')\n",
    "    \n",
    "display_missing(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Loading the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(f\"{path}/test.csv\", sep=\",\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Treating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove name and tickets\n",
    "\n",
    "2. map gender to:\n",
    "\n",
    "Male: 0<br>\n",
    "Female: 1\n",
    "\n",
    "3. Map Embarked to:\n",
    "\n",
    "* C: 0\n",
    "* Q: 1\n",
    "* S: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_sex = {'male': 0, 'female': 1}\n",
    "train_data = train_data.replace({'Sex': mapping_sex})\n",
    "test_data = test_data.replace({'Sex': mapping_sex})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_embarked = {'C': 0, 'Q': 1, 'S': 2}\n",
    "train_data = train_data.replace({'Embarked': mapping_embarked})\n",
    "test_data = test_data.replace({'Embarked': mapping_embarked})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to fill in the data that has no age. For this, let's try to find the correlation between age and other attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_corr = train_data.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "train_data_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
    "train_data_corr[train_data_corr['Feature 1'] == 'Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that there is a high correlation between age and Pclass, so we can use Pclass to try to fill in age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we have a suspicion that gender can greatly influence the average if we use social class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_by_pclass_sex = train_data.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "\n",
    "for pclass in range(1, 4):\n",
    "    # 0 - male, 1 - female\n",
    "    for sex in [1, 0]:\n",
    "        print('Average age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\n",
    "print('Average age of all: {}'.format(train_data['Age'].median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average age differs greatly between Pclass and gender. So we can use these two pieces of information to fill in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age'] = train_data.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_missing(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_missing(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to treat the missing cabins. The position of the place on the ship must influence survival (whoever crashed first may have died from the crash, for example).\n",
    "\n",
    "And we know that the organization is usually by social class. So let's try to relate the first letter of the cabin (which should be the sector) with the social class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting M for missing on missing data\n",
    "train_data['Cabin'] = train_data['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
    "test_data['Cabin'] = test_data['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Cabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to relate the lyrics to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_missing(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_missing(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cabin_corr = train_data.groupby(['Cabin', 'Pclass']).count().drop(columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', \n",
    "                                                                        'Fare', 'Embarked', 'PassengerId', 'Ticket']).rename(columns={'Name': 'Count'}).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cabin_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_cabin = {'A': 0, 'B': 0, 'C': 0, 'D': 1, 'E': 1, 'F': 2, 'G': 2, 'T': 2, 'M': 3}\n",
    "train_data = train_data.replace({'Cabin': mapping_cabin})\n",
    "test_data = test_data.replace({'Cabin': mapping_cabin})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_missing(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to treat the embarked, which has 2 missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_corr = train_data.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "train_data_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
    "train_data_corr[train_data_corr['Feature 1'] == 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[[col for col in train_data.columns if col not in ['Name', 'Ticket']]]\n",
    "test_data = test_data[[col for col in test_data.columns if col not in ['Name', 'Ticket']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_data.columns:\n",
    "    plt.figure(figsize=[16, 12])\n",
    "    train_data[col].plot()\n",
    "    plt.title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Import library packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_train_datax = train_data[[col for col in train_data.columns if col not in ['Survived']]]\n",
    "mlp_train_datay = train_data[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_x_train = mlp_train_datax.values.astype(np.float32)\n",
    "mlp_y_train = mlp_train_datay.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_x_test = test_data.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗ Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "mlp_x_train = scaler.fit_transform(mlp_x_train)\n",
    "mlp_x_test = scaler.transform(mlp_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗  Preparation of training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "mlp_y_train = np.eye(num_classes)[mlp_y_train.reshape(-1).astype(int)]\n",
    "mlp_y_train = torch.from_numpy(mlp_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = mlp_x_train.shape[1]\n",
    "hidden_size = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model compilation and optimizer definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adamax(mlp_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⊗  Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "mlp_x_train = torch.from_numpy(mlp_x_train)\n",
    "mlp_dataset = torch.utils.data.TensorDataset(mlp_x_train, mlp_y_train)\n",
    "mlp_dataloader = torch.utils.data.DataLoader(mlp_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.train()\n",
    "mlp_loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for inputs, targets in mlp_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mlp_model(inputs)\n",
    "        loss = criterion(outputs, torch.argmax(targets, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(mlp_dataloader)\n",
    "    mlp_loss_history.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.eval()\n",
    "with torch.no_grad():\n",
    "    mlp_y_pred = mlp_model(mlp_x_test)\n",
    "    mlp_predictions = torch.argmax(mlp_y_pred, dim=1)\n",
    "\n",
    "mlp_predictions = mlp_predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp_model.state_dict(), f\"{path}/mlp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(mlp_loss_history, color='blue')\n",
    "plt.title('Model loss', fontsize=20)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': mlp_predictions})\n",
    "output.to_csv(f\"{path}/mlp_submission.csv\", index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FolLqE_1bID"
   },
   "source": [
    "## Clear the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXiePpX31bID"
   },
   "source": [
    "Before moving on, please execute the following cell to clear up the CPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMB90WpX1bID",
    "outputId": "1df63f58-1161-495d-c481-2713ff31a7fa"
   },
   "outputs": [],
   "source": [
    "#import IPython\n",
    "#app = IPython.Application.instance()\n",
    "#app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear the temporary files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finishing the assessment, please execute the following cell to clear up the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../models/handwritten-model.pt ../datasets/cifar-10-python.tar.gz  ../datasets/cifar-10-batches-py ../datasets/cifar-10-batches-py ../datasets/MNIST  cifar-10*  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

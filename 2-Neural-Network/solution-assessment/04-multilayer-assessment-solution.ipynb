{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on finishing the MPL course!! Hopefully, you learned some valuable skills along the way and had fun doing it. Now it is time to put those skills to the test. In this assessment, you will train a new model capable of classifying the 10 different classes all included in the database known as [_CIFAR-10_](https://www.cs.toronto.edu/~kriz/cifar.html). You will need to get the model to a validation to pass the assessment, although we challenge you to do even better if you can. You will have to use the skills you learned in the previous exercises. Let's get started! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem: CIFAR-10 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "To start studying neural networks, it is necessary to understand and be able to apply the most basic concepts of recognition to your model. A good way to test and train your model is to use the CIFAR-10 database which consists of a set of $60,000$ images for $10$ different classes (planes, cars, birds, cats, deer, dogs, frogs, horses, ships and trucks) which are identified from $0$ to $9$ respectively. With that in mind, you will train your model on top of this base, making it possible to correctly recognize each element of these classes.\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    " <img src=\"../images/cifar-10.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of images from the CIFAR-10 database\n",
    "\n",
    "The images have dimensions of $32$x$32$ so remember to adjust your image when making a prediction with the model, for each class there are $6,000$ images related to its type so you must best adjust the number of training epochs as well as the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then:\n",
    "\n",
    "1. Create an MLP Neural Network.\n",
    "\n",
    "2. Import the CIFAR-10 database from the torchvision library.\n",
    "\n",
    "3. Train your model so that it correctly performs predictions, paying attention to the input parameters.\n",
    "\n",
    "4. Perform the prediction with some image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☆ Solution ☆ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "input_size = 3072  # input size (32 x 32)\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# Convert to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load torchvision CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./datasets', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Resize images to a one-dimensional vector\n",
    "        images = images.view(-1, input_size)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimzation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print the average loss each epoch\n",
    "    average_loss = total_loss / len(trainloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")\n",
    "\n",
    "image = Image.open('./images/validation-model-cifar10-cat.jpg') # Enter the path to your image here\n",
    "\n",
    "# Image pre-processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize to expected input size\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize pixel values\n",
    "])\n",
    "image = transform(image)\n",
    "\n",
    "# Add an extra dimension in the image tensor and resize image\n",
    "image = image.unsqueeze(0)\n",
    "image = image.view(-1, input_size)\n",
    "\n",
    "# Passing through the neural network\n",
    "model.eval()  # Change model mode to evaluation\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "\n",
    "# Results\n",
    "probabilities = torch.softmax(output, dim=1)\n",
    "predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "classes_Cifar10 = [\"Airplane\",\"Car\",\"Bird\",\"Cat\",\"Deer\",\"Dog\",\"Frog\",\"Horse\",\"Ship\",\"Truck\"]\n",
    "\n",
    "print(f\"Expected class: {classes_Cifar10[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FolLqE_1bID"
   },
   "source": [
    "## Clear the Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXiePpX31bID"
   },
   "source": [
    "Before moving on, please execute the following cell to clear up the CPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMB90WpX1bID",
    "outputId": "1df63f58-1161-495d-c481-2713ff31a7fa"
   },
   "outputs": [],
   "source": [
    "#import IPython\n",
    "#app = IPython.Application.instance()\n",
    "#app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear the Temporary Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finished the assessment, please execute the following cell to clear up the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../models/handwritten-model.pt ../datasets/cifar-10-python.tar.gz  ../datasets/cifar-10-batches-py ../datasets/cifar-10-batches-py ../datasets/MNIST  cifar-10*  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
